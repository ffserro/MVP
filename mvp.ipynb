{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "269fe9a4",
      "metadata": {
        "id": "269fe9a4"
      },
      "source": [
        "[![Abra no Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ffserro/MVP/blob/master/mvp.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wL7a42D2_9De",
      "metadata": {
        "id": "wL7a42D2_9De"
      },
      "source": [
        "# Regressão Linear para Series Temporais - Planejamento dos dispêndios de alimentação de militares da Marinha do Brasil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jkWGTW6eI5k9",
      "metadata": {
        "id": "jkWGTW6eI5k9"
      },
      "source": [
        "## Contextualização\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JgQOsnRyiCbK",
      "metadata": {
        "id": "JgQOsnRyiCbK"
      },
      "source": [
        "### O que é o municiamento?\n",
        "A Gestoria de Munciamento é o conjunto dos processos responsáveis por gerir diariamente a alimentação e subsistência dos militares e servidores lotados nas organizações militares da Marinha do Brasil.\n",
        "\n",
        "As principais atividades da gestoria de municiamento são:\n",
        "- Planejamento e aquisição de gêneros alimentícios\n",
        "- Controle de estoque de gêneros alimentícios\n",
        "- Escrituração e pagamento\n",
        "- Prestação de contas\n",
        "\n",
        "\n",
        "### Orçamento público e alimentação de militares\n",
        "Por ser custeada com recursos do orçamento da União, a gestoria de municiamento se submete a um sistema rigoroso de planejamento, controle, fiscalização e transparência, para garantir que os valores sejam utilizados de forma eficiente, econômica e legal.\n",
        "\n",
        "A compra de gêneros alimentícios é uma despesa recorrente e significativa. Uma gestão eficiente garante que os recursos financeiros sejam alocados de forma inteligente, evitando gastos desnecessários.\n",
        "\n",
        "Uma boa gestão de estoques minimiza desperdícios de alimentos por validade ou má conservação.\n",
        "\n",
        "Como em qualquer gasto público, a aquisição de suprimentos deve ser transparente e seguir todas as normas de controle, visando a economia e a responsabilidade fiscal."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9T92loE8Bgsx",
      "metadata": {
        "id": "9T92loE8Bgsx"
      },
      "source": [
        "<div align=\"justify\">\n",
        "O planejamento eficiente dos recursos logísticos é um dos pilares para a manutenção da prontidão e da capacidade operacional das Forças Armadas. Entre os diversos insumos estratégicos, a alimentação das organizações militares desempenha papel central, tanto no aspecto orçamentário quanto no suporte direto às atividades diárias. Na Marinha do Brasil, a gestão dos estoques e dos gastos com gêneros alimentícios envolve múltiplos órgãos e abrange um volume expressivo de transações financeiras e contábeis, tornando-se um processo complexo e suscetível a variações sazonais, econômicas e administrativas.\n",
        "\n",
        "Neste cenário, prever com maior precisão os custos relacionados ao consumo de alimentos é fundamental para otimizar a alocação de recursos públicos, reduzir desperdícios, evitar rupturas de estoque e aumentar a eficiência do planejamento orçamentário. Tradicionalmente, esse processo é conduzido por meio de análises históricas e técnicas de planejamento administrativo. No entanto, tais abordagens muitas vezes não capturam adequadamente os padrões temporais e as variáveis externas que influenciam os gastos.\n",
        "\n",
        "A ciência de dados, e em particular as técnicas de modelagem de séries temporais, surge como uma alternativa poderosa para aprimorar esse processo decisório. Modelos como SARIMA, Prophet, XGBoost e LSTM permitem identificar tendências, sazonalidades e anomalias nos dados, possibilitando não apenas previsões mais robustas, mas também a geração de insights que subsidiam políticas de abastecimento e aquisição.\n",
        "\n",
        "Assim, o presente trabalho propõe a aplicação de técnicas de análise e previsão de séries temporais sobre os dados históricos de consumo de alimentos da Marinha do Brasil, com o objetivo de estimar os custos futuros e explorar padrões relevantes que possam apoiar o processo de gestão logística e orçamentária. A relevância deste estudo reside não apenas no ganho potencial de eficiência administrativa, mas também na contribuição para a transparência, a racionalização do gasto público e a modernização da gestão de suprimentos em instituições estratégicas para o país.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CcOtcOjHAdVT",
      "metadata": {
        "id": "CcOtcOjHAdVT"
      },
      "source": [
        "## Glossário\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VlDqciiHAizg",
      "metadata": {
        "id": "VlDqciiHAizg"
      },
      "source": [
        "* Municiamento\n",
        "* Rancho\n",
        "* Etapa\n",
        "* Comensal\n",
        "* Série Temporal\n",
        "* Tendência\n",
        "* Sazonalidade\n",
        "* Estacionariedade\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EDC39fUr3nJB",
      "metadata": {
        "id": "EDC39fUr3nJB"
      },
      "source": [
        "## Modelagem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N_AvpbxG3uIJ",
      "metadata": {
        "id": "N_AvpbxG3uIJ"
      },
      "source": [
        "<div align=\"justify\">\n",
        " O conjunto de dados que será apresentado traz informações sobre despesas mensais com alimentação de militares e servidores de grandes organizações.\n",
        "\n",
        " O balanço de paiol do mês anterior nos traz a informação valor total dos gêneros alimentícios armazenados na organização no último dia do mês anterior.\n",
        "\n",
        " Os gêneros podem ser adquiridos pelas organizações de quatro formas diferentes:\n",
        " - adquirindo os gêneros dos depósitos de subsistência da Marinha\n",
        " - adquirindo os gêneros através de listas de fornecimento de gêneros, que são licitações centralizadas realizadas para atender toda a Marinha\n",
        " - adquirindo os gêneros através da realização de licitações próprias\n",
        " - adquirindo os gêneros através de contratação direta, sem licitação\n",
        "\n",
        " As organizações podem transferir gêneros entre seus estoques, através da realização de remessas. Os gêneros são contabilizados então no paiol através de remessas recebidas e remesas expedidas.\n",
        "\n",
        " Os gêneros consumidos durante as refeições do dia (café da manhã, almoço, janta e ceia) são contabilizados como gêneros consumidos.\n",
        "\n",
        " Os gêneros consumidos fora das refeições, como o biscoito, café e açúcar que são consumidos durante o dia, são contabilizados como vales-extra.\n",
        "\n",
        " As eventuais perdas de estoque são contabilizadas como termos de despesa.\n",
        "\n",
        " Quanto às receitas, cada comensal lotado na organização autoriza um determinado valor despesa por dia. A soma dessa despesa autorizada no mês é o valor limite dos gêneros que poderão ser retirados do paiol.\n",
        "\n",
        " A modelagem para os dispêndios com gêneros alimentícios considera as seguintes variáveis:\n",
        " - a quantidade de pessoas às quais é oferecida alimentação\n",
        " - o custo dos alimentos em paiol\n",
        " - a composição do cardápio (englobando o perfil de consumo de cada organização)\n",
        "\n",
        " Assim, o gasto mensal $Y_m$ de determinada organização no mês $m$ pode ser expresso em termos de:\n",
        " - Efetivo atendido ($N_m$)\n",
        " - Custo de aquisição dos insumos ($P_m$)\n",
        " - Composição do cardápio e perfil de consumo ($C_m$)\n",
        "\n",
        " Ou seja, $Y_m = f(N_m, P_m, C_m)\\ +\\ ϵ_m$\n",
        "\n",
        " sendo que o gasto mensal $Y_m$ é o somatório dos gastos diários $Y_d$, expressos por:\n",
        "\n",
        "\\begin{align}\n",
        "\\mathbf{Y_d} = \\sum_{i=1}^q \\ N_i \\cdot p_i \\\\ \\\\ \\mathbf{Y_m} = \\sum_{i=1}^{30} Y_{di}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3sDv8fXfJeYN",
      "metadata": {
        "id": "3sDv8fXfJeYN"
      },
      "source": [
        "## Trabalho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "IcDCsWxvPIxI",
      "metadata": {
        "id": "IcDCsWxvPIxI",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2c50d9-dfb7-43ed-f328-907611e4eec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MVP'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (196/196), done.\u001b[K\n",
            "remote: Compressing objects: 100% (174/174), done.\u001b[K\n",
            "remote: Total 196 (delta 98), reused 78 (delta 20), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (196/196), 6.09 MiB | 11.79 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "/bin/bash: line 1: nbstripout: command not found\n"
          ]
        }
      ],
      "source": [
        "#@title Downloads necessários\n",
        "\n",
        "# SE é a primeira vez que esta célula está sendo executada na sessão ENTÃO baixe os arquivos hospedados no github E instale as dependências do projeto.\n",
        "![ ! -f '/content/pip_log.txt' ] && git clone 'https://github.com/ffserro/MVP.git' && pip uninstall torchvision torch torchaudio -y > '/content/pip_log.txt' && pip install -r '/content/MVP/requirements.txt' > '/content/pip_log.txt' && nbstripout --install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "acb69f76",
      "metadata": {
        "id": "acb69f76"
      },
      "outputs": [],
      "source": [
        "#@title Import de bibliotecas\n",
        "\n",
        "from glob import glob # para referenciar grupos de arquivos durante a leitura\n",
        "\n",
        "from datetime import datetime as dt, timedelta as td # para manipulação de datas\n",
        "\n",
        "import itertools # para iterações eficientes\n",
        "\n",
        "import pandas as pd # para manipulação de dataframes\n",
        "import numpy as np # para cálculos numéricos eficientes\n",
        "\n",
        "# Para visualização de dados\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "from statsmodels import api as sm\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# Para modelos utilizados como baseline\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "# Para preparação dos dados\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Para avaliação dos modelos\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "from prophet import Prophet\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.models import NBEATS\n",
        "\n",
        "from autogluon.timeseries import TimeSeriesPredictor\n",
        "\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b106c1",
      "metadata": {
        "id": "c5b106c1"
      },
      "outputs": [],
      "source": [
        "#@title Leitura dos dados brutos\n",
        "mmm = pd.DataFrame()\n",
        "mmm = pd.concat([mmm] + [pd.read_excel(arquivo, parse_dates=[['ano', 'mes']]) for arquivo in glob('/content/MVP/dados/mmm/*.xlsx')])\n",
        "\n",
        "etapas = pd.DataFrame()\n",
        "etapas = pd.concat([etapas] + [pd.read_excel(arquivo, parse_dates=[['ano', 'mes']]) for arquivo in glob('/content/MVP/dados/etapas/*.xlsx')])\n",
        "\n",
        "centralizadas = pd.read_csv('/content/MVP/dados/om_centralizada.csv')\n",
        "\n",
        "om_info = pd.read_csv('/content/MVP/dados/om_info.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D2taCARVZEwt",
      "metadata": {
        "id": "D2taCARVZEwt"
      },
      "source": [
        "### Limpeza dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Un4l_KcXaoz6",
      "metadata": {
        "id": "Un4l_KcXaoz6"
      },
      "source": [
        "#### Limpeza do conjunto de dados sobre os Mapas Mensais do Municiamento de 2019 a 2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i7JCu7ZWalzw",
      "metadata": {
        "id": "i7JCu7ZWalzw"
      },
      "outputs": [],
      "source": [
        "mmm.groupby('nome').ano_mes.count().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q-s3ueiHa6Lu",
      "metadata": {
        "id": "q-s3ueiHa6Lu"
      },
      "outputs": [],
      "source": [
        "# Ao todo o conjunto de dados contempla 80 meses. Como será realizada uma análise de série temporal, vou considerar apenas as organizações que possuem dados para todo o período.\n",
        "mmm = mmm[mmm.codigo.isin(mmm.codigo.value_counts()[mmm.codigo.value_counts() == 80].index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4_xJLDpda_bB",
      "metadata": {
        "id": "4_xJLDpda_bB"
      },
      "outputs": [],
      "source": [
        "mmm = mmm[mmm.ano_mes < dt(2025, 7, 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WMzcvFijbCoc",
      "metadata": {
        "id": "WMzcvFijbCoc"
      },
      "source": [
        "#### Limpeza do conjunto de dados sobre informações das OM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J0gpOj7abIzH",
      "metadata": {
        "id": "J0gpOj7abIzH"
      },
      "outputs": [],
      "source": [
        "# Dados faltosos\n",
        "(om_info.isna().sum()/len(om_info)).sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WEaLd60hbRP_",
      "metadata": {
        "id": "WEaLd60hbRP_"
      },
      "outputs": [],
      "source": [
        "om_info.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_ZGPVcopbPZg",
      "metadata": {
        "id": "_ZGPVcopbPZg"
      },
      "outputs": [],
      "source": [
        "# Informações que não vao agregar conhecimento para o caso em tela, por serem nulos ou por conter informações irrelevantes\n",
        "om_info.drop(columns=['COMIMSUP', 'CNPJ', 'TELEFONE', 'ODS', 'TIPO_CONEXAO', 'CRIACAO', 'MODIFICACAO'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MsnEeL4abTYP",
      "metadata": {
        "id": "MsnEeL4abTYP"
      },
      "outputs": [],
      "source": [
        "om_info[['DN_ID', 'SUB_DN_ID', 'AREA_ID', 'COD_SQ_LOCAL', 'NOME', 'CIDADE']].sort_values(by=['DN_ID', 'SUB_DN_ID', 'AREA_ID', 'COD_SQ_LOCAL'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yg0iX83rbU5h",
      "metadata": {
        "id": "Yg0iX83rbU5h"
      },
      "outputs": [],
      "source": [
        "# As colunas SUB_DN_ID, AREA_ID e COD_SQ_LOCAL são pouco ou não descritivas\n",
        "om_info.drop(columns=['SUB_DN_ID', 'AREA_ID', 'COD_SQ_LOCAL'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iItk2qWRbV-N",
      "metadata": {
        "id": "iItk2qWRbV-N"
      },
      "outputs": [],
      "source": [
        "om_info.sort_values(by='TIPO')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ibe9IhfVbX00",
      "metadata": {
        "id": "Ibe9IhfVbX00"
      },
      "outputs": [],
      "source": [
        "# A variável TIPO começa descrevendo os tipo de organizações, como A para bases aeronavais, B para bases, F para fuzileiros navais, N para navios, S para saúde e I para instrução. Porém o T entra em uma categoria geral como se em algum momento essa vaiável deixou de ser utilizada.\n",
        "# Então se tornou pouco descritiva para os nossos objetivos\n",
        "\n",
        "om_info.drop(columns=['TIPO'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qFC_VhAGbY9P",
      "metadata": {
        "id": "qFC_VhAGbY9P"
      },
      "outputs": [],
      "source": [
        "om_info.loc[om_info.isna().sum(axis=1) != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qDD21OiibaRy",
      "metadata": {
        "id": "qDD21OiibaRy"
      },
      "outputs": [],
      "source": [
        "# Preenchendo manualmente os dados faltosos com informações da internet\n",
        "\n",
        "om_info.loc[om_info.CODIGO==87310, 'BAIRRO'] = 'Plano Diretor Sul'\n",
        "om_info.loc[om_info.CODIGO==87700, 'BAIRRO'] = 'Asa Sul'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IBy35wKwbcIT",
      "metadata": {
        "id": "IBy35wKwbcIT"
      },
      "source": [
        "#### Limpeza de dados do conjunto de dados sobre centralização do municiamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HBIVBMedbiqR",
      "metadata": {
        "id": "HBIVBMedbiqR"
      },
      "outputs": [],
      "source": [
        "# Primeira transformação a ser feita será padronizar a codificação das organizações por UASG\n",
        "\n",
        "centralizadas['OM_CENTRALIZADA_ID'] = centralizadas.OM_CENTRALIZADA_ID.map(om_info.set_index('ID').CODIGO)\n",
        "centralizadas['OM_CENTRALIZADORA_ID'] = centralizadas.OM_CENTRALIZADORA_ID.map(om_info.set_index('ID').CODIGO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R6UyXDrDbmGD",
      "metadata": {
        "id": "R6UyXDrDbmGD"
      },
      "outputs": [],
      "source": [
        "# Mais uma vez, eu só preciso das informações das organizações que estão presentes no conjunto de dados do Mapa Mensal do Municiamento\n",
        "centralizadas = centralizadas[centralizadas.OM_CENTRALIZADORA_ID.isin(mmm.codigo.unique())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xCN5KQq8bnaJ",
      "metadata": {
        "id": "xCN5KQq8bnaJ"
      },
      "outputs": [],
      "source": [
        "# Drop de colunas pouco informativas para o problema em tela\n",
        "\n",
        "centralizadas.drop(columns=['CONTATO', 'TELEFONE', 'CRIACAO', 'MODIFICACAO', 'GESTORIA_ID'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P4YlPXPzbowk",
      "metadata": {
        "id": "P4YlPXPzbowk"
      },
      "outputs": [],
      "source": [
        "# Remover do conjunto de dados as movimentações que aconteceram antes do período observado\n",
        "centralizadas = centralizadas[~(pd.to_datetime(centralizadas.DATA_FIM) < dt(2019, 1, 1))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LMybqLoNbqkc",
      "metadata": {
        "id": "LMybqLoNbqkc"
      },
      "outputs": [],
      "source": [
        "# Verificação manual da coerência dos períodos municiados\n",
        "\n",
        "centralizadas.groupby('OM_CENTRALIZADA_ID').filter(lambda x: len(x)> 1).sort_values(by=['OM_CENTRALIZADA_ID', 'DATA_INICIO'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XKRjKiMCbuBP",
      "metadata": {
        "id": "XKRjKiMCbuBP"
      },
      "outputs": [],
      "source": [
        "# Definindo algumas datas que as organizações passaram a ser centralizadas por outra centralizadora\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==11500) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==11500) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==49000) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==49000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==62000) & (centralizadas.OM_CENTRALIZADORA_ID==62000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==62000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==62500) & (centralizadas.OM_CENTRALIZADORA_ID==62500), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==62500) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==64000) & (centralizadas.OM_CENTRALIZADORA_ID==64000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==64000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==65701) & (centralizadas.OM_CENTRALIZADORA_ID==65701), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==65701) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==65730) & (centralizadas.OM_CENTRALIZADORA_ID==65701), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==65730) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==67000) & (centralizadas.OM_CENTRALIZADORA_ID==62000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==67000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==71000) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==71000) & (centralizadas.OM_CENTRALIZADORA_ID==71100), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==71000) & (centralizadas.OM_CENTRALIZADORA_ID==71100), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==71000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==72000) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==72000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==73000) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==73000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==73200) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==73200) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==76000) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==76000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==78000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==78000) & (centralizadas.OM_CENTRALIZADORA_ID==71000), 'DATA_INICIO']\n",
        "centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==80000) & (centralizadas.OM_CENTRALIZADORA_ID==80000), 'DATA_FIM'] = centralizadas.loc[(centralizadas.OM_CENTRALIZADA_ID==80000) & (centralizadas.OM_CENTRALIZADORA_ID==81000), 'DATA_INICIO']\n",
        "\n",
        "# Removendo algumas informações que estavam duplicadas\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==62600) & (centralizadas.OM_CENTRALIZADORA_ID==62600) & (centralizadas.TIPO_CENTRALIZACAO_ID.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==87400) & (centralizadas.OM_CENTRALIZADORA_ID==87400) & (centralizadas.TIPO_CENTRALIZACAO_ID.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==88000) & (centralizadas.OM_CENTRALIZADORA_ID==88000) & (centralizadas.TIPO_CENTRALIZACAO_ID.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==88133) & (centralizadas.OM_CENTRALIZADORA_ID==88133) & (centralizadas.TIPO_CENTRALIZACAO_ID.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==88701) & (centralizadas.OM_CENTRALIZADORA_ID==88000) & (centralizadas.DATA_FIM.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==95300) & (centralizadas.OM_CENTRALIZADORA_ID==95380) & (centralizadas.TIPO_CENTRALIZACAO_ID.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==95340) & (centralizadas.OM_CENTRALIZADORA_ID==95380) & (centralizadas.TIPO_CENTRALIZACAO_ID.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==95370) & (centralizadas.OM_CENTRALIZADORA_ID==95380) & (centralizadas.TIPO_CENTRALIZACAO_ID.isna())].index, inplace=True)\n",
        "centralizadas.drop(index=centralizadas[(centralizadas.OM_CENTRALIZADA_ID==95380) & (centralizadas.OM_CENTRALIZADORA_ID==95380) & (centralizadas.DATA_INICIO==dt(2004, 1, 1))].index, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "klA8qECFbvRI",
      "metadata": {
        "id": "klA8qECFbvRI"
      },
      "outputs": [],
      "source": [
        "# Supondo que as relações que não possuem data fim estão em vigor até hoje\n",
        "centralizadas.DATA_FIM.fillna(dt(2026,1,1), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4kc_m-hDbwnc",
      "metadata": {
        "id": "4kc_m-hDbwnc"
      },
      "source": [
        "#### Limpeza do conjunto de dados sobre etapas do municiamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eTK5TjYb0xh",
      "metadata": {
        "id": "8eTK5TjYb0xh"
      },
      "outputs": [],
      "source": [
        "# Filtro para manter apenas etapas que sejam relevantes dado as organizações contantes do conjunto de dados dos Mapas Mensais do Municiamento\n",
        "etapas = etapas[etapas.uasg.isin(mmm.codigo.unique())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nz_1qH87b23h",
      "metadata": {
        "id": "nz_1qH87b23h"
      },
      "outputs": [],
      "source": [
        "# Removendo as etapas de complementos, uma vez que o objetivo da contabilização das etapas é contar o número de pessoas de cada organização\n",
        "etapas = etapas[~(etapas.codigo_etapa//100==6)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pNsMWpnjcAfp",
      "metadata": {
        "id": "pNsMWpnjcAfp"
      },
      "source": [
        "#### Salvando os dados limpos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iaJ1PP35b_me",
      "metadata": {
        "id": "iaJ1PP35b_me"
      },
      "outputs": [],
      "source": [
        "mmm.to_csv('/content/MVP/dados/mmm/mmm_limpo.csv', index=False)\n",
        "om_info.to_csv('/content/MVP/dados/om_info_limpo.csv', index=False)\n",
        "centralizadas.to_csv('/content/MVP/dados/om_centralizada_limpo.csv', index=False)\n",
        "etapas.to_csv('/content/MVP/dados/etapas/etapas_limpo.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sbYdXOLiEqAY",
      "metadata": {
        "id": "sbYdXOLiEqAY"
      },
      "source": [
        "### Exploração"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d23b319b",
      "metadata": {
        "id": "d23b319b"
      },
      "outputs": [],
      "source": [
        "mmm_marinha = mmm.groupby(['ano_mes'])[['totais_balanco_paiol_despesa']].sum().reset_index().rename(columns={'totais_balanco_paiol_despesa':'consumo'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81640c41",
      "metadata": {
        "id": "81640c41"
      },
      "outputs": [],
      "source": [
        "mmm_marinha = mmm_marinha.iloc[:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jVCau_ZSeEzU",
      "metadata": {
        "id": "jVCau_ZSeEzU"
      },
      "outputs": [],
      "source": [
        "mmm_marinha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f51d785",
      "metadata": {
        "id": "0f51d785"
      },
      "outputs": [],
      "source": [
        "mmm_etapas = pd.merge(left=mmm, right=etapas, how='inner', left_on=['ano_mes', 'codigo'], right_on=['ano_mes', 'uasg'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fe04974",
      "metadata": {
        "id": "4fe04974"
      },
      "outputs": [],
      "source": [
        "# Filtra o dataframe mmm_etapas para incluir apenas os códigos de etapa 103 e 105,\n",
        "# que representam diferentes tipos de refeições ou etapas de municiamento.\n",
        "# Em seguida, seleciona as colunas 'ano_mes', 'nome', 'codigo_etapa' e 'quantidade'\n",
        "# para visualização.\n",
        "mmm_etapas[mmm_etapas.codigo_etapa.isin([103, 105])][['ano_mes', 'nome', 'codigo_etapa', 'quantidade']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XdujXVSmQD-H",
      "metadata": {
        "id": "XdujXVSmQD-H"
      },
      "source": [
        "### Funções úteis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066e46ec",
      "metadata": {
        "id": "066e46ec"
      },
      "outputs": [],
      "source": [
        "def plota_resultados(df, x_col, y_col, title, preds=None, labels=None):\n",
        "    \"\"\"\n",
        "    Plota a série temporal original e, opcionalmente, as previsões de um ou mais modelos.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame contendo a série temporal original.\n",
        "        x_col (str): Nome da coluna do eixo x (geralmente a coluna de data).\n",
        "        y_col (str): Nome da coluna do eixo y (a variável a ser plotada).\n",
        "        title (str): Título do gráfico.\n",
        "        preds (dict, optional): Dicionário onde as chaves são os nomes dos modelos\n",
        "                                 e os valores são tuplas (x_pred, y_pred) com as\n",
        "                                 datas e os valores previstos. Defaults to None.\n",
        "        labels (dict, optional): Dicionário para renomear os rótulos dos eixos\n",
        "                                 no gráfico. Defaults to {x_col: \"Período\", y_col: \"Valor observado\"}.\n",
        "    \"\"\"\n",
        "    # Série real\n",
        "    fig = px.line(\n",
        "        df,\n",
        "        x=x_col,\n",
        "        y=y_col,\n",
        "        labels=labels or {x_col: \"Período\", y_col: \"Valor observado\"},\n",
        "        title=title\n",
        "    )\n",
        "\n",
        "    # Previsões opcionais\n",
        "    if preds:\n",
        "        for model_name, (x_pred, y_pred) in preds.items():\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=x_pred,\n",
        "                y=y_pred,\n",
        "                mode=\"lines+markers\",\n",
        "                name=f\"Previsão — {model_name}\",\n",
        "                line=dict(width=2, dash=\"dash\")\n",
        "            ))\n",
        "\n",
        "    # Layout padronizado\n",
        "    fig.update_traces(line=dict(width=2))\n",
        "    fig.update_xaxes(tickangle=45)\n",
        "    fig.update_layout(\n",
        "        template=\"plotly_white\",\n",
        "        hovermode=\"x unified\"\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Gera o plot da série temporal original dos gastos com alimentação\n",
        "fig = plota_resultados(\n",
        "df=mmm_marinha,\n",
        "x_col=\"ano_mes\",\n",
        "y_col=\"consumo\",\n",
        "title=\"Gastos com alimentação dos últimos cinco anos\"\n",
        ")\n",
        "\n",
        "# Exibe o gráfico\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5HTsVvFHEco_",
      "metadata": {
        "id": "5HTsVvFHEco_"
      },
      "source": [
        "### Verificações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc3e4dff",
      "metadata": {
        "id": "fc3e4dff"
      },
      "outputs": [],
      "source": [
        "# Teste de estacionariedade\n",
        "\n",
        "def checa_estacionariedade(serie, alpha=0.05):\n",
        "  resultado = adfuller(serie.dropna())\n",
        "  p_valor = resultado[1]\n",
        "  print(\"Estatítica ADF:\", resultado[0])\n",
        "  print(\"p-valor:\", p_valor)\n",
        "  if p_valor < alpha:\n",
        "    print(\"Série estacionária (rejeita hipótese nula de raiz unitária).\")\n",
        "  else:\n",
        "    print(\"Série não estacionária (não rejeita a hipótese nula).\")\n",
        "\n",
        "checa_estacionariedade(mmm_marinha.consumo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mQPb3Dg5Ev5D",
      "metadata": {
        "id": "mQPb3Dg5Ev5D"
      },
      "outputs": [],
      "source": [
        "# Decomposição de tendência e sazonalidade\n",
        "\n",
        "decomp = seasonal_decompose(mmm_marinha.consumo, model='additive', period=12)\n",
        "decomp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gUJDBObHEzh1",
      "metadata": {
        "id": "gUJDBObHEzh1"
      },
      "outputs": [],
      "source": [
        "# Análise de autocorrelação\n",
        "\n",
        "fig, ax = plt.subplots(2,1, figsize=(12,8))\n",
        "plot_acf(mmm_marinha.consumo.dropna(), lags=36, ax=ax[0])\n",
        "plot_pacf(mmm_marinha.consumo.dropna(), lags=36, ax=ax[1], method='ywm')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NDTP4fiN91tf",
      "metadata": {
        "id": "NDTP4fiN91tf"
      },
      "outputs": [],
      "source": [
        "autocorr_values = pd.DataFrame({i:[mmm_marinha.consumo.autocorr(lag=i)] for i in range(1, 50)}).T\n",
        "\n",
        "autocorr_values[abs(autocorr_values[0]) >= 0.3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0mYyWRosQH0C",
      "metadata": {
        "id": "0mYyWRosQH0C"
      },
      "source": [
        "### Teste de modelos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = mmm_marinha.iloc[:-12]\n",
        "test = mmm_marinha.iloc[-12:]"
      ],
      "metadata": {
        "id": "d8dtYUKvigHi"
      },
      "id": "d8dtYUKvigHi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "-07Wb9xwSs4S",
      "metadata": {
        "id": "-07Wb9xwSs4S"
      },
      "source": [
        "#### Previsão Naïve (critério de comparação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c6cb01",
      "metadata": {
        "id": "80c6cb01"
      },
      "outputs": [],
      "source": [
        "naive_forecast = mmm_marinha.consumo.shift(1)\n",
        "mae_naive = mean_absolute_error(mmm_marinha.consumo.iloc[1:], naive_forecast.iloc[1:])\n",
        "print('Baseline Naïve MAE:', mae_naive)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6vQyvOIWS05M",
      "metadata": {
        "id": "6vQyvOIWS05M"
      },
      "source": [
        "#### Previsão SARIMA (critério de comparação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbd40b6",
      "metadata": {
        "id": "3cbd40b6"
      },
      "outputs": [],
      "source": [
        "# Espaço de busca\n",
        "p = d = q = range(0, 3)       # ARIMA (p,d,q)\n",
        "P = D = Q = range(0, 2)       # sazonal (P,D,Q)\n",
        "m = 12                        # periodicidade (mensal -> 12)\n",
        "\n",
        "pdq = list(itertools.product(p, d, q))\n",
        "seasonal_pdq = list(itertools.product(P, D, Q, [m]))\n",
        "\n",
        "best_aic = np.inf\n",
        "best_order, best_seasonal = None, None\n",
        "best_model = None\n",
        "\n",
        "for order in pdq:\n",
        "    for seasonal_order in seasonal_pdq:\n",
        "        try:\n",
        "            model = sm.tsa.statespace.SARIMAX(\n",
        "                mmm_marinha.consumo,\n",
        "                order=order,\n",
        "                seasonal_order=seasonal_order,\n",
        "                enforce_stationarity=False,\n",
        "                enforce_invertibility=False\n",
        "            )\n",
        "            results = model.fit(disp=False)\n",
        "            if results.aic < best_aic:\n",
        "                best_aic = results.aic\n",
        "                best_order, best_seasonal = order, seasonal_order\n",
        "                best_model = results\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "print(f\"Melhor modelo SARIMA encontrado: order={best_order}, seasonal_order={best_seasonal}, AIC={best_aic:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = (1, 2, 2)\n",
        "seasonal_order = (0, 1, 1, 12)\n",
        "\n",
        "model = SARIMAX(\n",
        "    train.consumo,\n",
        "    order=order,\n",
        "    seasonal_order=seasonal_order,\n",
        "    enforce_stationarity=False,\n",
        "    enforce_invertibility=False\n",
        ")\n",
        "\n",
        "res = model.fit(disp=False, maxiter=200)\n",
        "print(res.summary().tables[1])\n",
        "\n",
        "pred = res.get_forecast(steps=12)\n",
        "y_pred = pred.predicted_mean\n",
        "\n",
        "bias = abs(test.consumo - y_pred).mean()\n",
        "\n",
        "y_pred_no_bias = y_pred - bias\n",
        "\n",
        "print(f'SARIMA MAE: {mean_absolute_error(test['consumo'], y_pred_no_bias)}')"
      ],
      "metadata": {
        "id": "Ye0h5frgOGgT"
      },
      "id": "Ye0h5frgOGgT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — SARIMA\",\n",
        "    preds={\n",
        "        \"SARIMA\": (test.ano_mes, y_pred_no_bias)\n",
        "    }\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "K71MGq_bfNgz"
      },
      "id": "K71MGq_bfNgz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "qqIYoFrQTRrO",
      "metadata": {
        "id": "qqIYoFrQTRrO"
      },
      "source": [
        "#### Exponential Smoothing (critério de comparação)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aec5d4b",
      "metadata": {
        "id": "4aec5d4b"
      },
      "outputs": [],
      "source": [
        "# Configurações do modelo Holt-Winters\n",
        "hw_config = {\n",
        "    \"trend\": \"add\",          # tendência aditiva\n",
        "    \"seasonal\": \"add\",       # sazonalidade aditiva\n",
        "    \"seasonal_periods\": 12   # sazonalidade anual (12 meses, se dados forem mensais)\n",
        "}\n",
        "\n",
        "# Instancia e ajusta o modelo\n",
        "hw_model = ExponentialSmoothing(\n",
        "    train.consumo,\n",
        "    **hw_config\n",
        ").fit(\n",
        "    optimized=True,          # busca automática dos melhores parâmetros de suavização\n",
        "    use_brute=True           # garante exploração mais ampla dos parâmetros\n",
        ")\n",
        "\n",
        "# Geração de previsões para o horizonte definido\n",
        "forecast_horizon = 12\n",
        "pred_hw = hw_model.forecast(steps=forecast_horizon)\n",
        "\n",
        "# Avaliação rápida\n",
        "print(f'Previsão gerada para {forecast_horizon} períodos à frente.')\n",
        "print(f'Holt-Winters MAE: {mean_absolute_error(test['consumo'], pred_hw)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d782840",
      "metadata": {
        "id": "8d782840"
      },
      "outputs": [],
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — ExponentialSmoothing\",\n",
        "    preds={\n",
        "        \"ExponentialSmoothing\": (test.ano_mes, pred_hw)\n",
        "    }\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tfo6DUp-TBlL",
      "metadata": {
        "id": "Tfo6DUp-TBlL"
      },
      "source": [
        "#### Prophet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678e5898",
      "metadata": {
        "id": "678e5898"
      },
      "outputs": [],
      "source": [
        "prophet_df = (\n",
        "    mmm_marinha[['ano_mes', 'consumo']]\n",
        "    .rename(columns={'ano_mes': 'ds', 'consumo': 'y'})\n",
        "    .assign(ds=lambda d: pd.to_datetime(d['ds'], format='%m_%Y'))\n",
        "    .sort_values('ds')\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "model_prophet = Prophet(\n",
        "    yearly_seasonality=True,\n",
        "    weekly_seasonality=False,\n",
        "    daily_seasonality=False,\n",
        "    seasonality_mode=\"additive\",\n",
        "    interval_width=0.95\n",
        ")\n",
        "\n",
        "model_prophet.fit(prophet_df)\n",
        "\n",
        "forecast_horizon = 12  # meses à frente\n",
        "future = model_prophet.make_future_dataframe(periods=forecast_horizon, freq='M')\n",
        "forecast = model_prophet.predict(future)\n",
        "\n",
        "test_dates = pd.to_datetime(test['ano_mes'], format='%m_%Y')\n",
        "forecast_test = forecast.set_index('ds').loc[test_dates]\n",
        "\n",
        "y_true = test['consumo']\n",
        "prophet_y_pred = forecast_test['yhat']\n",
        "\n",
        "mae = mean_absolute_error(y_true, prophet_y_pred)\n",
        "rmse = mean_squared_error(y_true, prophet_y_pred)\n",
        "\n",
        "print(f\"Prophet — MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f7c19f3",
      "metadata": {
        "id": "2f7c19f3"
      },
      "outputs": [],
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — Prophet\",\n",
        "    preds={\n",
        "        \"Prophet\": (test.ano_mes, prophet_y_pred)\n",
        "    }\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2toQJB6hTFbt",
      "metadata": {
        "id": "2toQJB6hTFbt"
      },
      "source": [
        "#### XGBoost regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a4064f",
      "metadata": {
        "id": "b2a4064f"
      },
      "outputs": [],
      "source": [
        "xg_df = mmm_marinha[['consumo']]\n",
        "\n",
        "for lag in [1, 3, 6]:\n",
        "  xg_df[f'lag{lag}'] = xg_df['consumo'].shift(lag)\n",
        "\n",
        "for window in [3, 6]:\n",
        "  xg_df[f'rolling{window}'] = xg_df['consumo'].rolling(window).mean()\n",
        "\n",
        "xg_df = xg_df.dropna().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b9e0724",
      "metadata": {
        "id": "0b9e0724"
      },
      "outputs": [],
      "source": [
        "horizon = 12  # número de períodos para teste\n",
        "train_xg, test_xg = xg_df.iloc[:-horizon], xg_df.iloc[-horizon:]\n",
        "\n",
        "X_train, y_train = train_xg.drop(columns=[\"consumo\"]), train_xg[\"consumo\"]\n",
        "X_test, y_test   = test_xg.drop(columns=[\"consumo\"]), test_xg[\"consumo\"]\n",
        "\n",
        "xgb_params = dict(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,               # usa todos os núcleos disponíveis\n",
        "    objective=\"reg:squarederror\",  # regressão padrão\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "xgb_model = XGBRegressor(**xgb_params)\n",
        "\n",
        "# Treino\n",
        "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "\n",
        "pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, pred_xgb)\n",
        "rmse = mean_squared_error(y_test, pred_xgb)\n",
        "\n",
        "print(f\"XGBoost MAE: {mae:.2f} | RMSE: {rmse:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "610a55a9",
      "metadata": {
        "id": "610a55a9"
      },
      "outputs": [],
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — XGBoost\",\n",
        "    preds={\n",
        "        \"XGBoost\": (test.ano_mes, pred_xgb)\n",
        "    }\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mV8L6DMLTW-T",
      "metadata": {
        "id": "mV8L6DMLTW-T"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3bfe4c",
      "metadata": {
        "id": "1a3bfe4c"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "despesas_scaled = scaler.fit_transform(mmm_marinha.consumo.values.reshape(-1, 1))\n",
        "\n",
        "def create_sequences(data, window=12):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)- window):\n",
        "        X.append(data[i:i+window])\n",
        "        y.append(data[i+window])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = create_sequences(despesas_scaled)\n",
        "\n",
        "\n",
        "split = len(X) - 12\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "print('Shape treino:', X_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4973a6",
      "metadata": {
        "id": "dd4973a6"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    LSTM(128, activation='relu', return_sequences=True, input_shape=(12, 1)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    LSTM(64, activation='relu', return_sequences=False),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "\n",
        "    Dense(16, activation='relu'),\n",
        "\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compilação com Adam otimizado\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=0.999),\n",
        "    loss='mae',\n",
        "    metrics=['mse']\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=200, min_lr=1e-5, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=16,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab14322",
      "metadata": {
        "id": "8ab14322"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "\n",
        "mae_lstm = mean_absolute_error(y_test_inv, y_pred_inv)\n",
        "print('LSTM MAE:', mae_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc0090f",
      "metadata": {
        "id": "bfc0090f"
      },
      "outputs": [],
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — LSTM\",\n",
        "    preds={\n",
        "        \"LSTM\": (test.ano_mes, y_pred_inv.flatten())\n",
        "    }\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5M6EqDdRTalL",
      "metadata": {
        "id": "5M6EqDdRTalL"
      },
      "source": [
        "#### Multistep LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf8a44c",
      "metadata": {
        "id": "bdf8a44c"
      },
      "outputs": [],
      "source": [
        "def create_sequences_multistep(data, window=12, horizon=12):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window - horizon + 1):\n",
        "        X.append(data[i:i+window])\n",
        "        y.append(data[i+window:i+window+horizon].flatten())\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "window = 12\n",
        "horizon = 12\n",
        "X, y = create_sequences_multistep(despesas_scaled, window, horizon)\n",
        "\n",
        "split = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('y_train, shape:', y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d401850",
      "metadata": {
        "id": "0d401850"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    LSTM(128, activation='relu', return_sequences=True, input_shape=(window, 1)),\n",
        "    # Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    LSTM(64, activation='relu', return_sequences=False),\n",
        "    # Dropout(0.3),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "\n",
        "    Dense(horizon)  # saída multi-step\n",
        "])\n",
        "\n",
        "# Compilação\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\n",
        "    loss=\"mse\",\n",
        "    metrics=[\"mae\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=200, min_lr=1e-5, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=2000,\n",
        "    batch_size=16,          # batch maior estabiliza gradiente\n",
        "    validation_data = (X_test, y_test),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ef65ad",
      "metadata": {
        "id": "07ef65ad"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_test_inv = scaler.inverse_transform(y_test)\n",
        "y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "\n",
        "mae_lstm_multi = mean_absolute_error(y_test_inv.flatten(), y_pred_inv.flatten())\n",
        "print('LSTM Multi-step MAE:', mae_lstm_multi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3ae83a",
      "metadata": {
        "id": "5a3ae83a"
      },
      "outputs": [],
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — Multi-step LSTM\",\n",
        "    preds={\n",
        "        \"Multi-step LSTM\": (test.ano_mes, y_pred_inv[-1])\n",
        "    }\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D1MgfHeFXe6s",
      "metadata": {
        "id": "D1MgfHeFXe6s"
      },
      "source": [
        "#### N-Beats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6cda0ff",
      "metadata": {
        "id": "e6cda0ff"
      },
      "outputs": [],
      "source": [
        "train['item_id'] = 'mnc'\n",
        "nbeats_data = train.rename(columns={'item_id':'unique_id', 'ano_mes':'ds', 'consumo':'y'})\n",
        "\n",
        "model = NBEATS(\n",
        "    h = 12,\n",
        "    input_size = 36,\n",
        "    stack_types = ['seasonality', 'identity', 'trend', 'identity'],\n",
        "    n_blocks = [3, 3, 3, 2],\n",
        "    activation = 'ReLU',\n",
        "\n",
        "    learning_rate = 1e-3,\n",
        "    num_lr_decays = 3,\n",
        "    batch_size = 16,\n",
        "    scaler_type = 'robust',\n",
        "\n",
        "\n",
        "    max_steps = 1000,\n",
        "    val_check_steps = 10,\n",
        "    early_stop_patience_steps = 20\n",
        ")\n",
        "\n",
        "nbeats_forecast = NeuralForecast(models=[model], freq='M')\n",
        "nbeats_forecast.fit(df=nbeats_data, val_size=12)\n",
        "y_pred_nbeats = nbeats_forecast.predict()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — N-Beats\",\n",
        "    preds={\n",
        "        \"N-Beats\": (test.ano_mes, y_pred_nbeats.NBEATS.values.flatten())\n",
        "    }\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "vTEP6ZTytjB8"
      },
      "id": "vTEP6ZTytjB8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Autogluon"
      ],
      "metadata": {
        "id": "msJ331VFVejD"
      },
      "id": "msJ331VFVejD"
    },
    {
      "cell_type": "code",
      "source": [
        "autogluon_data = nbeats_data.rename(columns={'unique_id':'item_id', 'ds':'timestamp', 'y':'target'})\n",
        "\n",
        "prediction_length = 12\n",
        "\n",
        "train_df = autogluon_data.iloc[:-prediction_length].copy()\n",
        "test_df  = autogluon_data.iloc[-prediction_length:].copy()\n",
        "\n",
        "val_size = prediction_length  # validação com mesmo horizonte\n",
        "train_for_fit = autogluon_data.iloc[:-val_size].copy()\n",
        "tune_for_fit = autogluon_data.iloc[-val_size - prediction_length : -prediction_length].copy()  # segmento anterior ao teste\n",
        "\n",
        "predictor = TimeSeriesPredictor(\n",
        "    target='target',\n",
        "    prediction_length=prediction_length,\n",
        "    eval_metric='MAE'\n",
        ")\n",
        "\n",
        "predictor.fit(\n",
        "    train_data=train_for_fit,\n",
        "    presets='best_quality',\n",
        "    time_limit=None,\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "# Simples: usamos o conjunto completo (AutoGluon deduz o ponto de corte pelo prediction_length)\n",
        "predictions = predictor.predict(autogluon_data)"
      ],
      "metadata": {
        "id": "iUGj0T7uVjOo"
      },
      "id": "iUGj0T7uVjOo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plota_resultados(\n",
        "    df=mmm_marinha,\n",
        "    x_col=\"ano_mes\",\n",
        "    y_col=\"consumo\",\n",
        "    title=\"Previsão temporal — Autogluon\",\n",
        "    preds={\n",
        "        \"Autogluon\": (test.ano_mes, predictions['mean'].values)\n",
        "    }\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "VgX3VA0TWujd"
      },
      "id": "VgX3VA0TWujd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "MmTXRrVdTith",
      "metadata": {
        "id": "MmTXRrVdTith"
      },
      "source": [
        "### Seleção do melhor modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #@title Comparação de modelos\n",
        "# import ipywidgets as widgets\n",
        "# from IPython.display import display, clear_output\n",
        "\n",
        "# # Dropdowns interativos\n",
        "# model_dropdown = widgets.Dropdown(\n",
        "#     options=[\"SARIMAX\", \"Prophet\", \"XGBoost\", \"ExponentialSmoothing\", \"LSTM\", \"N-BEATS\", \"AutoGluon\"],\n",
        "#     value=\"LSTM\",\n",
        "#     description=\"Modelo:\"\n",
        "# )\n",
        "\n",
        "# test_dropdown = widgets.Dropdown(\n",
        "#     options=[\"A\", \"B\", \"C\"],\n",
        "#     value=\"A\",\n",
        "#     description=\"Teste:\"\n",
        "# )\n",
        "\n",
        "# output = widgets.Output()\n",
        "\n",
        "# def update_plot(change):\n",
        "#     with output:\n",
        "#         clear_output()\n",
        "#         model = model_dropdown.value\n",
        "#         test_set = test_dropdown.value\n",
        "\n",
        "#         print(f\"📊 Modelo selecionado: {model}\")\n",
        "#         print(f\"📂 Conjunto de teste : {test_set}\")\n",
        "\n",
        "#         # Seleção de previsão\n",
        "#         if model == \"LSTM\":\n",
        "#             y_pred = pred_lstm\n",
        "#         elif model == \"XGBoost\":\n",
        "#             y_pred = pred_xgb\n",
        "#         elif model == \"Prophet\":\n",
        "#             y_pred = forecast_test['yhat']\n",
        "#         elif model == \"SARIMAX\":\n",
        "#             y_pred = pred_sarimax\n",
        "#         elif model == \"ExponentialSmoothing\":\n",
        "#             y_pred = pred_hw\n",
        "#         elif model == \"N-BEATS\":\n",
        "#             y_pred = y_pred_nbeats\n",
        "#         elif model == \"AutoGluon\":\n",
        "#             y_pred = y_pred_autogluon\n",
        "\n",
        "#         # Plot interativo\n",
        "#         fig = grafico_base(f\"Previsão temporal com {model}\")\n",
        "#         fig.add_scatter(x=test.ano_mes, y=y_pred, mode=\"lines+markers\", name=f\"{model} Forecast\")\n",
        "#         fig.show()\n",
        "\n",
        "# # Ligando evento\n",
        "# model_dropdown.observe(update_plot, names=\"value\")\n",
        "# test_dropdown.observe(update_plot, names=\"value\")\n",
        "\n",
        "# display(model_dropdown, test_dropdown, output)\n",
        "\n",
        "# # Render inicial\n",
        "# update_plot(None)\n"
      ],
      "metadata": {
        "id": "_Y2-2hodalJy"
      },
      "id": "_Y2-2hodalJy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "A4JcV4jXYCrE",
      "metadata": {
        "id": "A4JcV4jXYCrE"
      },
      "source": [
        "### Conclusões"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "elR7bye6YFZn",
      "metadata": {
        "id": "elR7bye6YFZn"
      },
      "source": [
        "## Trabalhos futuros"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}